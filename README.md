# Awesome-Dexterous-Manipulation [![Awesome](https://awesome.re/badge-flat.svg)](https://awesome.re) [![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

To include your papers, please submit a new issue or pull request with the titles and necessary details. Thank you.

## Content

- [Awesome-Dexterous-Manipulation  ](#awesome-dexterous-manipulation--)
  - [Content](#content)
  - [Teleoperation](#teleoperation)
  - [Reinforcement Learning](#reinforcement-learning)
  - [Learning From Human](#learning-from-human)
  - [Sim2Real](#sim2real)
  - [Hardware](#hardware)
  - [Tactile Sensing](#tactile-sensing)
  - [VLA](#vla)
  - [Cool Idea](#cool-idea)

## Teleoperation

* [RSS 2025] Liu, Jason Jingzhou, et al. "Factr: Force-attending curriculum training for contact-rich policy learning." - [paper](https://arxiv.org/abs/2502.17432)
* [RSS 2024] Wang, C., Shi, H., Wang, W., Zhang, R., Fei-Fei, L., & Liu, C. K. (2024). Dexcap: Scalable and portable mocap data collection system for dexterous manipulation. - [arXiv](https://arxiv.org/abs/2403.07788), [Website](https://dex-cap.github.io/)
* [RSS 2023] Qin, Y., Yang, W., Huang, B., Van Wyk, K., Su, H., Wang, X., ... & Fox, D. (2023). Anyteleop: A general vision-based dexterous robot arm-hand teleoperation system. - [arXiv](https://arxiv.org/abs/2307.04577), [Website](https://yzqin.github.io/anyteleop/)
* [ICRA 2023] Arunachalam, S. P., GÃ¼zey, I., Chintala, S., & Pinto, L. (2023, May). Holo-dex: Teaching dexterity with immersive mixed reality. - [arXiv](https://arxiv.org/abs/2210.06463), [Website](https://holo-dex.github.io/)
* [ICRA 2020] Handa, A., Van Wyk, K., Yang, W., Liang, J., Chao, Y. W., Wan, Q., ... & Fox, D. (2020, May). Dexpilot: Vision-based teleoperation of dexterous robotic hand-arm system. - [arXiv](https://arxiv.org/abs/1910.03135), [Website](https://sites.google.com/view/dex-pilot)

## Reinforcement Learning

- [ICRA 2025] Ankile, L., Simeonov, A., Shenfeld, I., Torne, M., & Agrawal, P. (2024). From Imitation to Refinement--Residual RL for Precise Assembly. - [arXiv](https://arxiv.org/abs/2407.16677)

## Learning From Human

* [arXiv] Kareer, S., Patel, D., Punamiya, R., Mathur, P., Cheng, S., Wang, C., ... & Xu, D. (2024). Egomimic: Scaling imitation learning via egocentric video. - [arXiv](https://arxiv.org/abs/2410.24221), [Website](https://egomimic.github.io/)
* [CoRL 2022] Shaw, K., Bahl, S., & Pathak, D. (2023, March). Videodex: Learning dexterity from internet videos. - [arXiv](https://arxiv.org/abs/2212.04498), [Website](https://video-dex.github.io)
* [arXiv] Qiu, R. Z., Yang, S., Cheng, X., Chawla, C., Li, J., He, T., ... & Wang, X. (2025). Humanoid Policy~ Human Policy. - [arXiv](https://arxiv.org/abs/2503.13441), [Website](https://human-as-robot.github.io/)

## Sim2Real

* [RSS 2023] Huang, B., Chen, Y., Wang, T., Qin, Y., Yang, Y., Atanasov, N., & Wang, X. (2023). Dynamic handover: Throw and catch with bimanual hands. - [arXiv](https://arxiv.org/pdf/2309.05655), [Website](https://binghao-huang.github.io/dynamic_handover/)
* [IROS 2023] Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments - [arXiv](https://arxiv.org/abs/2301.04195), [Website](https://isaac-orbit.github.io/)
* [Science Robotics 2023] Chen, T., Tippur, M., Wu, S., Kumar, V., Adelson, E., & Agrawal, P. (2023). Visual dexterity: In-hand reorientation of novel and complex object shapes.  - [paper](https://arxiv.org/abs/2211.11744)
* [RSS 2025] Maddukuri, A., Jiang, Z., Chen, L. Y., Nasiriany, S., Xie, Y., Fang, Y., ... & Zhu, Y. (2025). Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation.  - [arXiv](https://co-training.github.io/resources/paper.pdf), [website](https://co-training.github.io/)
* Lin, T., Sachdev, K., Fan, L., Malik, J., & Zhu, Y. (2025). Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids. - [arXiv](https://arxiv.org/abs/2502.20396)

## Hardware

* [IROS 2024] Romero, B., Fang, H. S., Agrawal, P., & Adelson, E. (2024, October). Eyesight hand: Design of a fully-actuated dexterous robot hand with integrated vision-based tactile sensors and compliant actuation. In 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (pp. 1853-1860). IEEE. - [arXiv](https://arxiv.org/abs/2410.06440)
* [Humanoids 2023] Mannam, P., Shaw, K., Bauer, D., Oh, J., Pathak, D., & Pollard, N. (2023, December). Designing anthropomorphic soft hands through interaction. In 2023 IEEE-RAS 22nd International Conference on Humanoid Robots (Humanoids) (pp. 1-8). IEEE. - [arXiv](https://arxiv.org/pdf/2306.04784)
* [RSS 2023] Shaw, K., Agarwal, A., & Pathak, D. (2023). Leap hand: Low-cost, efficient, and anthropomorphic hand for robot learning. - [arXiv](https://arxiv.org/abs/2309.06440)
* [Nature Communications] Kim, U., Jung, D., Jeong, H., Park, J., Jung, H. M., Cheong, J., ... & Park, C. (2021). Integrated linkage-driven dexterous anthropomorphic robotic hand. Nature communications, 12(1), 1-13. - [Paper](https://www.nature.com/articles/s41467-021-27261-0.pdf)
* [ICRA 2012] Bridgwater, L. B., Ihrke, C. A., Diftler, M. A., Abdallah, M. E., Radford, N. A., Rogers, J. M., ... & Linn, D. M. (2012, May). The robonaut 2 hand-designed to do work with tools. In 2012 IEEE International Conference on Robotics and Automation (pp. 3425-3430). IEEE. - [Paper](https://ieeexplore.ieee.org/abstract/document/6224772/)

## Tactile Sensing

- [ICRA 2021] Dong, S., Jha, D. K., Romeres, D., Kim, S., Nikovski, D., & Rodriguez, A. (2021, May). Tactile-rl for insertion: Generalization to objects of unknown geometry. - [arXiv](https://arxiv.org/pdf/2104.01167)
- [RAL] Q. Wu, H. Wang, J. Zhou, X. Xiong and Y. Lou. (2025) "TARS: Tactile Affordance in Robot Synesthesia for Dexterous Manipulation" - [Paper](https://ieeexplore.ieee.org/abstract/document/10766612)
- [ICRA 2025] Wu, T., Li, J., Zhang, J., Wu, M., & Dong, H. (2024). Canonical representation and force-based pretraining of 3d tactile for dexterous visuo-tactile policy learning.  - [arXiv](https://arxiv.org/abs/2409.17549)
- [arXiv] Li, J., Wu, T., Zhang, J., Chen, Z., Jin, H., Wu, M., ... & Dong, H. (2025). Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation. - [arXiv](https://arxiv.org/abs/2505.13982), [Website](https://adaptac-dex.github.io/)

## VLA

* [2024]Kim, M. J., Pertsch, K., Karamcheti, S., Xiao, T., Balakrishna, A., Nair, S., ... & Finn, C. (2024). Openvla: An open-source vision-language-action model. - [arXiv](https://arxiv.org/abs/2406.09246), [website](https://openvla.github.io/)

## Cool Idea

* [CoRL 2023] Zakka, K., Wu, P., Smith, L., Gileadi, N., Howell, T., Peng, X. B., ... & Abbeel, P. (2023). Robopianist: Dexterous piano playing with deep reinforcement learning.  *-* [arXiv](https://arxiv.org/abs/2304.04150), [Code](https://kzakka.com/robopianist/), [Website](https://github.com/google-research/robopianist)
